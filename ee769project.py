# -*- coding: utf-8 -*-
"""EE769Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SsFQ6Dpqa_PK0xO-_yA7DZ7f5AJ_IyhJ

Importing Data
"""

!pip install prophet
!pip install neuralprophet==<compatible version with PyTorch 1.13.1>

import yfinance as yf
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import statsmodels.api as sm
from statsmodels.tsa.stattools import adfuller
from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_percentage_error
from statsmodels.tsa.holtwinters import SimpleExpSmoothing
from statsmodels.tsa.holtwinters import ExponentialSmoothing
from sklearn.preprocessing import PowerTransformer
from statsmodels.tsa.arima.model import ARIMA
from prophet import Prophet
# from neuralprophet import NeuralProphet
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LSTM

msft = yf.Ticker("TSLA")

df = msft.history("2y","1d")

df.reset_index(level = 0, inplace = True)

df.columns

df = df[['Date', 'Close']]
df['Date'] = df['Date'].apply(lambda x: x.date())
df.info()

df['Date'] = pd.to_datetime(df['Date'])
df.head()

"""Handling Missing Values"""

date_range = pd.date_range(start=df['Date'].min(), end=df['Date'].max())

df1 = df.set_index('Date').reindex(date_range).fillna({'Price': None}).reset_index()
df1 = df1.rename(columns={'index': 'Date'})

df1.tail()

df1.isnull().sum()

#Imputing missing values with exponential moving average
ema = df1['Close'].ewm(span= 2, min_periods=2).mean()
df1['Close'].fillna(ema, inplace = True)
df1.isnull().sum()

"""Exploratory Data Analysis"""

sns.boxplot(df1['Close'])
plt.show()

"""No Outliers in the data"""

df1.describe()

#Visualizing the time series
plt.figure(figsize=(18,4))
plt.plot(df1['Date'],df1['Close'], label = 'Price')
plt.xlabel('Date')
plt.ylabel('Stock Price')
plt.title('Time Series of Stock Price Over the year')
plt.legend()

"""Additive seasonal decomposition is a time series analysis technique that decomposes a time series into four components: trend, seasonality, cyclical, and residual.

In additive seasonal decomposition, the time series is modeled as the sum of the four components:

y(t) = Trend(t) + Seasonality(t) + Cyclical(t) + Residual(t)

"""

df1.index = df1.Date
decomposition = sm.tsa.seasonal_decompose(df1.Close, model='additive',period = 30)

fig, (ax1, ax2, ax3, ax4) = plt.subplots(4, 1, figsize=(12,8))
decomposition.observed.plot(ax=ax1)
ax1.set_ylabel('Observed')
decomposition.trend.plot(ax=ax2)
ax2.set_ylabel('Trend')
decomposition.seasonal.plot(ax=ax3)
ax3.set_ylabel('Seasonal')
decomposition.resid.plot(ax=ax4)
ax4.set_ylabel('Residual')
fig.suptitle('Seasonal Decomposition')
plt.tight_layout()
plt.show()

"""Multiplicative seasonal decomposition is a time series analysis technique that decomposes a time series into three components: trend, seasonality, and residual.

In additive seasonal decomposition, the time series is modeled as the sum of the four components:

y(t) = Trend(t)xSeasonality(t)xResidual(t)
"""

df1.index = df1.Date
decomposition1 = sm.tsa.seasonal_decompose(df1.Close, model='multiplicative',period = 30)

fig1, (ax1, ax2, ax3, ax4) = plt.subplots(4, 1, figsize=(12,8))
decomposition1.observed.plot(ax=ax1)
ax1.set_ylabel('Observed')
decomposition.trend.plot(ax=ax2)
ax2.set_ylabel('Trend')
decomposition.seasonal.plot(ax=ax3)
ax3.set_ylabel('Seasonal')
decomposition.resid.plot(ax=ax4)
ax4.set_ylabel('Residual')
fig1.suptitle('Seasonal Decomposition')
plt.tight_layout()
plt.show()

"""###Checking If Data is Stationary"""

#Augmented Dickey-Fuller (ADF) test
adf_test = adfuller(df1['Close'])
print('p-value:',adf_test[1])

"""p-value > 0.05, Therefore data is non-stationary

#Forecasting with various models

We choose Root Mean Squared Error(RMSE) and Mean Absolute Percentage Error(MAPE) to compare the models. Lower the value of RMSE and MAPE, better is the model
"""

#Splitting the data
train_len = 365
train = df1[0 : train_len]
test = df1[train_len : ]

"""##1. Simple Moving Average"""

df1_sma = df1.copy()
df1_sma['forecast'] = df1_sma['Close'].rolling(12).mean()

#Plotting test Vs Forecast
plt.figure(figsize=(18,4))
plt.plot(test['Close'], label = 'test')
plt.plot(df1_sma['forecast'][train_len:], label = 'Forecasted')
plt.xlabel('Date')
plt.ylabel('Stock Price')
plt.title('Simple Moving Average')
plt.legend()

#Calculating RMSE and MAPE
rmse_sma = mean_squared_error(test['Close'], df1_sma['forecast'][train_len:], squared=False)
mape_sma = mean_absolute_percentage_error(test['Close'], df1_sma['forecast'][train_len:])
print('Root Mean Squared Error:', rmse_sma)
print(' Mean Absolute Percentage Error', mape_sma)

"""##2. Exponential Smoothing Techniques

###2.1 *Simple Exponential Smoothing*
"""

model = SimpleExpSmoothing(train['Close'])
fit = model.fit(optimized=True)
df1_ses = test.copy()
df1_ses['forecast'] = fit.forecast(test.shape[0])

#Plotting test Vs Forecast
plt.figure(figsize=(18,4))
plt.plot(test['Close'], label = 'test')
plt.plot(df1_ses['forecast'], label = 'Forecasted')
plt.xlabel('Date')
plt.ylabel('Stock Price')
plt.title('Simple Exponential Smoothing')
plt.legend()

#Calculating RMSE and MAPE
rmse_ses = mean_squared_error(test['Close'], df1_ses['forecast'], squared=False)
mape_ses = mean_absolute_percentage_error(test['Close'], df1_ses['forecast'])
print('Root Mean Squared Error:', rmse_ses)
print(' Mean Absolute Percentage Error', mape_ses)

"""###2.2 Holt Winters' additive method with trend and seasonality


"""

model = ExponentialSmoothing(np.asarray(train['Close']) ,seasonal_periods=12 ,trend='add', seasonal='add')
fit = model.fit(optimized=True)
df1_holtadd = test.copy()
df1_holtadd['forecast'] = fit.forecast(test.shape[0])

#Plotting test Vs Forecast
plt.figure(figsize=(18,4))
plt.plot(test['Close'], label = 'test')
plt.plot(df1_holtadd['forecast'], label = 'Forecasted')
plt.xlabel('Date')
plt.ylabel('Stock Price')
plt.title('Holt Winters additive method with trend and seasonality')
plt.legend()

#Calculating RMSE and MAPE
rmse_holtadd = mean_squared_error(test['Close'], df1_holtadd['forecast'], squared=False)
mape_holtadd = mean_absolute_percentage_error(test['Close'], df1_holtadd['forecast'])
print('Root Mean Squared Error:', rmse_holtadd)
print(' Mean Absolute Percentage Error', mape_holtadd)

"""###2.2 Holt Winters' multiplicative method with trend and seasonality"""

model = ExponentialSmoothing(np.asarray(train['Close']) ,seasonal_periods=12 ,trend='mul', seasonal='mul')
fit = model.fit(optimized=True)
df1_holtmul = test.copy()
df1_holtmul['forecast'] = fit.forecast(len(test))

#Plotting test Vs Forecast
plt.figure(figsize=(18,4))
plt.plot(test['Close'], label = 'test')
plt.plot(df1_holtmul['forecast'], label = 'Forecasted')
plt.xlabel('Date')
plt.ylabel('Stock Price')
plt.title('Holt Winters multiplicative method with trend and seasonality')
plt.legend()

#Calculating RMSE and MAPE
rmse_holtmul = mean_squared_error(test['Close'], df1_holtmul['forecast'], squared=False)
mape_holtmul = mean_absolute_percentage_error(test['Close'], df1_holtmul['forecast'])
print('Root Mean Squared Error:', rmse_holtmul)
print(' Mean Absolute Percentage Error', mape_holtmul)

"""#3 Autoregressive Methods

First we need to make data stationary since these models assume stationary data i.e constant variance and mean. For this we will perform transformation and differencing
"""

#Transforming the data
pt = PowerTransformer()
pt.fit(train['Close'].values.reshape(-1,1))
train_arp = pd.Series(pt.transform(train['Close'].values.reshape(-1,1)).flatten(), index = train.index)
test_arp = pd.Series(pt.transform(test['Close'].values.reshape(-1,1)).flatten(), index = test.index)

#Differrencing the data
train_ar = train_arp.diff().dropna()
test_ar = test_arp.diff().dropna()

adf_test = adfuller(train_ar)
print('p-value:',adf_test[1])

adf_test = adfuller(test_ar)
print('p-value:',adf_test[1])

"""Both p-values < 0.05, Hence Data is stationary now

##3.1 Auto Regressive model (ARMA)
"""

model = ARIMA(train_ar, order=(2,0,1))
fit = model.fit()
df1_arma = test_ar.to_frame()
df1_arma.head()
df1_arma['forecast'] = fit.predict(df1_arma.index.min(), df1_arma.index.max())
df1_arma['forecast'] = df1_arma['forecast'].cumsum()
df1_arma['forecast'] = df1_arma['forecast'] + train_arp[-1]
df1_arma['forecast'] = pt.inverse_transform(df1_arma['forecast'].values.reshape(-1,1))
df1_arma.head()

#Plotting test Vs Forecast
plt.figure(figsize=(18,4))
plt.plot(test['Close'], label = 'test')
plt.plot(df1_arma['forecast'], label = 'Forecasted')
plt.xlabel('Date')
plt.ylabel('Stock Price')
plt.title('Auto Regressive moving average (ARMA)')
plt.legend()

#Calculating RMSE and MAPE
rmse_arma = mean_squared_error(test['Close'][1:], df1_arma['forecast'], squared=False)
mape_arma = mean_absolute_percentage_error(test['Close'][1:], df1_arma['forecast'])
print('Root Mean Squared Error:', rmse_arma)
print(' Mean Absolute Percentage Error', mape_arma)

"""##3.2 Auto regressive integrated moving average (ARIMA)

"""

model = ARIMA(train_ar, order=(1, 1, 1))
fit = model.fit()
df1_arima = test_ar.to_frame()
df1_arima.head()
df1_arima['forecast'] = fit.predict(df1_arima.index.min(), df1_arima.index.max())
df1_arima['forecast'] = df1_arima['forecast'].cumsum() + train_arp[-1]
df1_arima['forecast'] = pt.inverse_transform(df1_arima['forecast'].values.reshape(-1,1))
df1_arima.head()

#Plotting test Vs Forecast
plt.figure(figsize=(18,4))
plt.plot(test['Close'], label = 'test')
plt.plot(df1_arima['forecast'], label = 'Forecasted')
plt.xlabel('Date')
plt.ylabel('Stock Price')
plt.title('Auto Regressive integrated moving average (ARIMA)')
plt.legend()

#Calculating RMSE and MAPE
rmse_arima = mean_squared_error(test['Close'][1:], df1_arima['forecast'], squared=False)
mape_arima = mean_absolute_percentage_error(test['Close'][1:], df1_arima['forecast'])
print('Root Mean Squared Error:', rmse_arima)
print(' Mean Absolute Percentage Error', mape_arima)

"""##3.3 Seasonal Auto Regressive integrated moving average (SARIMA)

"""

model = ARIMA(train_ar, order=(1, 1, 1),seasonal_order=(0, 1, 1, 6))
fit = model.fit()
df1_sarima = test_ar.to_frame()
df1_sarima.head()
df1_sarima['forecast'] = fit.predict(df1_sarima.index.min(), df1_sarima.index.max())
df1_sarima['forecast'] = df1_sarima['forecast'].cumsum() + train_arp[-1]
df1_sarima['forecast'] = pt.inverse_transform(df1_sarima['forecast'].values.reshape(-1,1))
df1_sarima.head()

#Plotting test Vs Forecast
plt.figure(figsize=(18,4))
plt.plot(test['Close'], label = 'test')
plt.plot(df1_sarima['forecast'], label = 'Forecasted')
plt.xlabel('Date')
plt.ylabel('Stock Price')
plt.title('Seasonal Auto Regressive integrated moving average (SARIMA)')
plt.legend()

#Calculating RMSE and MAPE
rmse_sarima = mean_squared_error(test['Close'][1:], df1_sarima['forecast'], squared=False)
mape_sarima = mean_absolute_percentage_error(test['Close'][1:], df1_sarima['forecast'])
print('Root Mean Squared Error:', rmse_sarima)
print(' Mean Absolute Percentage Error', mape_sarima)

"""#4. Prophet Model"""

model = Prophet( changepoint_range=0.5,changepoint_prior_scale=1)

train_prophet = train.copy()
train_prophet = train_prophet.rename(columns={'Date': 'ds', 'Close': 'y'})

test_prophet = test.copy()
test_prophet = test_prophet.rename(columns={'Date': 'ds', 'Close': 'y'})

model.fit(train_prophet)

future = model.make_future_dataframe(periods=len(test))
forecast = model.predict(future)
forecast = forecast[-len(test):]
forecast.index = test_prophet.index

#Plotting test Vs Forecast
plt.figure(figsize=(18,4))
plt.plot(test['Close'], label = 'test')
plt.plot(forecast['yhat'], label = 'Forecasted')
plt.xlabel('Date')
plt.ylabel('Stock Price')
plt.title('Prophet for Forecating')
plt.legend()

#Calculating RMSE and MAPE
rmse_prophet = mean_squared_error(test['Close'], forecast['yhat'], squared=False)
mape_prophet = mean_absolute_percentage_error(test['Close'], forecast['yhat'])
print('Root Mean Squared Error:', rmse_sarima)
print(' Mean Absolute Percentage Error', mape_sarima)

"""##5. LSTM"""

scaler = MinMaxScaler()
scaler = MinMaxScaler()
train_lstm = scaler.fit_transform(train[['Close']])
test_lstm = scaler.transform(test[['Close']])

def create_sequences(data, seq_length):
    X = []
    y = []
    for i in range(seq_length, len(data)):
        X.append(data[i-seq_length:i])
        y.append(data[i, :])
    return np.array(X), np.array(y)

seq_length = 10
X_train, y_train = create_sequences(train_lstm, seq_length)
X_test, y_test = create_sequences(test_lstm, seq_length)

model = Sequential()
model.add(LSTM(units=50, return_sequences=True, input_shape=(seq_length, 1)))
model.add(LSTM(units=50))
model.add(Dense(units=1))

model.compile(optimizer='adam', loss='mean_squared_error')
model.fit(X_train, y_train, epochs=50, batch_size=32)

y_pred = model.predict(X_test)
y_pred = scaler.inverse_transform(y_pred)
y_test = scaler.inverse_transform(y_test)

#Plotting test Vs Forecast
plt.figure(figsize=(18,4))
plt.plot(test.index[seq_length:], y_test[:, 0], label='test')
plt.plot(test.index[seq_length:], y_pred[:, 0], label='Forecasted')
plt.xlabel('Date')
plt.ylabel('Stock Price')
plt.title('LSTM')
plt.legend()
plt.show()

#Calculating RMSE and MAPE
rmse_lstm = mean_squared_error(y_test[:, 0], y_pred[:, 0], squared=False)
mape_lstm = mean_absolute_percentage_error(y_test[:, 0], y_pred[:, 0])
print('Root Mean Squared Error:', rmse_lstm)
print(' Mean Absolute Percentage Error', mape_lstm)

results = pd.DataFrame({'Models': ['Simple Moving Average', 'Simple Exponential Smoothing','Holt Winters' +'additive method with trend and seasonality','Holt Winters' +'multiplicative method with trend and seasonality','ARMA','ARIMA','SARIMA', 'Prophet','LSTM' ],
                        'RMSE':[rmse_sma,rmse_ses,rmse_holtadd,rmse_holtmul,rmse_arma,rmse_arima, rmse_sarima,rmse_prophet, rmse_lstm],
                        'MAPE':[mape_sma,mape_ses,mape_holtadd,mape_holtmul,mape_arma,mape_arima, mape_sarima,mape_prophet, mape_lstm],
                        })
results

results.to_csv('results.csv', index = False)

